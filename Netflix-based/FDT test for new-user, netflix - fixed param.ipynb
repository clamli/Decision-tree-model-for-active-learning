{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDTree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import klepto\n",
    "import shelve\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'netflix/sparse_matrix_100%.npz'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3d0296ec3a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrating_matrix_csc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'netflix/sparse_matrix_100%.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrating_matrix_val_csc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'netflix/sparse_matrix_validation_75%.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file load DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rcg/software/Linux/Ubuntu/16.04/amd64/LANG/PYTHON/3.5.2-SYSTEM/lib/python3.5/site-packages/scipy/sparse/_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mPICKLE_KWARGS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rcg/software/Linux/Ubuntu/16.04/amd64/LANG/PYTHON/3.5.2-SYSTEM/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'netflix/sparse_matrix_100%.npz'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "rating_matrix_csc = load_npz('netflix/sparse_matrix_100%.npz').tocsc()\n",
    "rating_matrix_val_csc = load_npz('netflix/sparse_matrix_validation_75%.npz').tocsc()\n",
    "print(\"file load DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rating_matrix_csc' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c10a983021f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m''' Save to file 'tree.pkl' '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_matrix_csc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rating_matrix_csc' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "start = 0\n",
    "end = int(rating_matrix_csc.shape[1] * 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DecisionTreeModel:\n",
    "    def __init__(self, source, depth_threshold=10, plambda=7, MSP_item=200):\n",
    "        self.sMatrix = source\n",
    "        self.real_item_num = source.shape[0]\n",
    "        self.global_mean = 0  # global average of ratings   \n",
    "        self.depth_threshold = depth_threshold\n",
    "        self.plambda = plambda\n",
    "        self.cur_depth = 0\n",
    "        self.MSP_item = MSP_item\n",
    "\n",
    "        #### Calculate rate of progress ####\n",
    "        self.node_num = 0\n",
    "        self.cur_node = 0\n",
    "        for i in range(self.depth_threshold):\n",
    "            self.node_num += 3 ** i\n",
    "\n",
    "        \n",
    "        #### Initiate Tree, lr_bound ####\n",
    "        self.tree = list(range(1, self.sMatrix.shape[1]))\n",
    "        self.split_item = []\n",
    "        self.lr_bound = {'0': [[0, len(self.tree) - 1]]}\n",
    "        self.global_mean = source.sum()/source.getnnz()\n",
    "\n",
    "        #### Generate bias, sum_cur_t, sum_2_cur_t ####\n",
    "        #### Generate rI, rU ####\n",
    "        \n",
    "        self.rU = {}        \n",
    "        for dictname in range(151):\n",
    "            d = shelve.open('./rU_data/'+str(dictname), protocol = pickle.HIGHEST_PROTOCOL)\n",
    "            self.rU.update(d['content'])\n",
    "            d.close()\n",
    "        print(\"rU DONE\")\n",
    "        \n",
    "#         self.biasUM = load_npz('netflix/biasUM.npz').tocsc()\n",
    "#         print(\"biasUM DONE\")\n",
    "        \n",
    "        Tree = klepto.archives.dir_archive('treeFile', {}, serialized=True)\n",
    "        Tree.load()\n",
    "        self.biasU       = Tree[\"biasU\"]\n",
    "        self.sum_cur_t   = Tree[\"sum_cur_t\"]\n",
    "        self.sum_2_cur_t = Tree[\"sum_2_cur_t\"]\n",
    "        self.sum_cntt    = Tree[\"sum_cntt\"]\n",
    "        self.rI          = Tree[\"rI\"]\n",
    "        self.item_size = len(self.rI)\n",
    "        self.user_size = len(self.tree)        \n",
    "        print(\"Initiation DONE!\")\n",
    "\n",
    "    def calculate_error(self, sumt, sumt_2, cntt):\n",
    "        ''' Calculate error for one item-split in one node '''\n",
    "        Error_i = np.sum(sumt_2 - (sumt ** 2) / (cntt + 1e-9))\n",
    "\n",
    "        return Error_i\n",
    "\n",
    "    def generate_decision_tree(self, lr_bound_for_node, chosen_id):\n",
    "        '''\n",
    "            sumtL: dict {\n",
    "                itemid1: {'rating': sum of ratings for item 1, 'cnt': sum of users rated item 1}\n",
    "                itemid2: {'rating': sum of ratings for item 2, 'cnt': sum of users rated item 2}\n",
    "                ...\n",
    "            }\n",
    "            sumtL_2: dict {\n",
    "                itemid1: sum of square ratings for item 1\n",
    "                itemid2: sum of square ratings for item 2\n",
    "                ...\n",
    "            }\n",
    "            lr_bound_for_node: list [leftind, rightind] for one node\n",
    "        '''\n",
    "\n",
    "        #### Terminate ####\n",
    "        self.cur_depth += 1\n",
    "        if self.cur_depth > self.depth_threshold or len(chosen_id) == self.item_size:\n",
    "            return\n",
    "\n",
    "        #### Choose Most Popular Items of This Node ####\n",
    "        num_rec = np.zeros(self.real_item_num)\n",
    "        for userid in self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1] + 1)]:\n",
    "            user_all_rating_id = np.array(list(self.rU[userid].keys()))\n",
    "            num_rec[user_all_rating_id[:]] += 1\n",
    "        sub_item_id = np.argsort(num_rec)[:self.MSP_item]\n",
    "\n",
    "        #### Find optimum item to split ####\n",
    "        min_sumtL, min_sumtD, min_sumtL_2, min_sumtD_2, min_sumtU, min_sumtU_2, Error = {}, {}, {}, {}, {}, {}, {}\n",
    "        min_Error = \"None\"\n",
    "        for itemid in sub_item_id:\n",
    "#             print(itemid)\n",
    "            if itemid in chosen_id:\n",
    "                continue\n",
    "            '''\n",
    "                user_rating_item_in_nodet: np.array([ [uid01, rating01], [uid02, rating02], ... ])\n",
    "                to find all users in node t who rates item i\n",
    "            '''           \n",
    "            user_rating_item_in_nodet = np.array([[userid, self.rU[userid][itemid]] for userid in\n",
    "                                         self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1] + 1)] if\n",
    "                                         itemid in self.rU[userid]])\n",
    "#             sumt = np.zeros((self.real_item_num, 3))\n",
    "#             sumt_2 = np.zeros((self.real_item_num, 3))\n",
    "#             cntt = np.zeros((self.real_item_num, 3))\n",
    "\n",
    "#             lst_L = list(user_rating_item_in_nodet[user_rating_item_in_nodet[:, 1] >= 4, 0])\n",
    "#             lst_D = list(user_rating_item_in_nodet[user_rating_item_in_nodet[:, 1] <= 3, 0])\n",
    "\n",
    "#             realML = self.sMatrix[:, lst_L] - self.biasUM[:, lst_L]\n",
    "#             realMD = self.sMatrix[:, lst_D] - self.biasUM[:, lst_D]\n",
    "#             sumt[:, 0] = (realML).sum(axis=1).T\n",
    "#             sumt_2[:, 0] = (realML.power(2)).sum(axis=1).T\n",
    "#             cntt[:, 0] = self.sMatrix[:, lst_L].getnnz(axis=1).T\n",
    "#             sumt[:, 1] = (realMD).sum(axis=1).T\n",
    "#             sumt_2[:, 1] = (realMD.power(2)).sum(axis=1).T\n",
    "#             cntt[:, 1] = self.sMatrix[:, lst_L].getnnz(axis=1).T\n",
    "            \n",
    "            sumt = np.zeros((self.real_item_num, 3))\n",
    "            sumt_2 = np.zeros((self.real_item_num, 3))\n",
    "            cntt = np.zeros((self.real_item_num, 3))\n",
    "            for user in user_rating_item_in_nodet:\n",
    "                ''' user_all_rating: array [ [itemid11, rating11], [itemid12, rating12], ... ] '''\n",
    "                user_all_rating_id = np.array(list(self.rU[user[0]].keys()))\n",
    "                user_all_rating = np.array(list(self.rU[user[0]].values()))\n",
    "                #### calculate sumtL for node LIKE ####\n",
    "                if user[1] >= 4:\n",
    "                    sumt[user_all_rating_id[:], 0] += user_all_rating[:] - self.biasU[user[0]]\n",
    "                    sumt_2[user_all_rating_id[:], 0] += (user_all_rating[:] - self.biasU[user[0]]) ** 2\n",
    "                    cntt[user_all_rating_id[:], 0] += 1\n",
    "                #### calculate sumtD for node DISLIKE ####\n",
    "                elif user[1] <= 3:\n",
    "                    sumt[user_all_rating_id[:], 1] += user_all_rating[:] - self.biasU[user[0]]\n",
    "                    sumt_2[user_all_rating_id[:], 1] += (user_all_rating[:] - self.biasU[user[0]]) ** 2\n",
    "                    cntt[user_all_rating_id[:], 1] += 1\n",
    "\n",
    "            #### calculate sumtU for node UNKNOWN ####\n",
    "            sumt[:, 2] = self.sum_cur_t[:] - sumt[:, 0] - sumt[:, 1]\n",
    "            sumt_2[:, 2] = self.sum_2_cur_t[:] - sumt_2[:, 0] - sumt_2[:, 1]\n",
    "            cntt[:, 2] = self.sum_cntt[:] - cntt[:, 0] - cntt[:, 1]\n",
    "            Error[itemid] = self.calculate_error(sumt, sumt_2, cntt)\n",
    "\n",
    "            if min_Error == \"None\" or Error[itemid] < min_Error:\n",
    "                min_sumt = sumt\n",
    "                min_sumt_2 = sumt_2\n",
    "                min_cntt = cntt\n",
    "                min_Error = Error[itemid]\n",
    "        #### Find optimum split-item ####\n",
    "        optimum_itemid = min(Error, key=Error.get)\n",
    "        if len(self.split_item) == self.cur_depth - 1:\n",
    "            self.split_item.append([optimum_itemid])\n",
    "        else:\n",
    "            self.split_item[self.cur_depth - 1].append(optimum_itemid)\n",
    "        # self.split_item.setdefault(str(self.cur_depth-1), []).append(optimum_itemid)\n",
    "        chosen_id.append(optimum_itemid)\n",
    "        print(\"split item found!\")\n",
    "        #### sort tree ####\n",
    "        self.lr_bound.setdefault(str(self.cur_depth), []).append([])  # for LIKE\n",
    "        self.lr_bound[str(self.cur_depth)].append([])  # for DISLIKE\n",
    "        self.lr_bound[str(self.cur_depth)].append([])  # for UNKNOWN\n",
    "        listU, listL, listD = [], [], []\n",
    "        for userid in self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1] + 1)]:\n",
    "            if optimum_itemid not in self.rU[userid]:\n",
    "                listU.append(userid)\n",
    "            elif self.rU[userid][optimum_itemid] >= 4:\n",
    "                listL.append(userid)\n",
    "            elif self.rU[userid][optimum_itemid] <= 3:\n",
    "                listD.append(userid)\n",
    "        self.tree[lr_bound_for_node[0]:(lr_bound_for_node[1] + 1)] = listL + listD + listU\n",
    "        self.lr_bound[str(self.cur_depth)][-3] = [lr_bound_for_node[0],\n",
    "                                                  lr_bound_for_node[0] + len(listL) - 1]  # for LIKE\n",
    "        self.lr_bound[str(self.cur_depth)][-2] = [lr_bound_for_node[0] + len(listL),\n",
    "                                                  lr_bound_for_node[0] + len(listL) + len(listD) - 1]  # for DISLIKE\n",
    "        self.lr_bound[str(self.cur_depth)][-1] = [lr_bound_for_node[0] + len(listL) + len(listD),\n",
    "                                                  lr_bound_for_node[0] + len(listL) + len(listD) + len(\n",
    "                                                      listU) - 1]  # for UNKNOWN\n",
    "\n",
    "        #### Generate Subtree of Node LIKE ####\n",
    "        self.sum_cur_t = min_sumt[:, 0]\n",
    "        self.sum_2_cur_t = min_sumt_2[:, 0]\n",
    "        self.sum_cntt = min_cntt[:, 0]\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-3], chosen_id[:])\n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Generate Subtree of Node DISLIKE ####\n",
    "        self.sum_cur_t = min_sumt[:, 1]\n",
    "        self.sum_2_cur_t = min_sumt_2[:, 1]\n",
    "        self.sum_cntt = min_cntt[:, 1]\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-2], chosen_id[:])\n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Generate Subtree of Node UNKNOWN ####\n",
    "        self.sum_cur_t = min_sumt[:, 2]\n",
    "        self.sum_2_cur_t = min_sumt_2[:, 2]\n",
    "        self.sum_cntt = min_cntt[:, 2]\n",
    "        self.generate_decision_tree(self.lr_bound[str(self.cur_depth)][-1], chosen_id[:])\n",
    "        self.cur_depth -= 1\n",
    "\n",
    "        #### Show Rating Progress ####\n",
    "        for i in range(self.cur_depth - 1):\n",
    "            print(\"┃\", end=\"\")\n",
    "        print(\"┏\", end=\"\")\n",
    "        self.cur_node += 1\n",
    "        print(\"Current depth: \" + str(self.cur_depth) + \"        %.2f%%\" % (100 * self.cur_node / self.node_num))\n",
    "\n",
    "   \n",
    "    def build_model(self):\n",
    "        #### Construct the tree & get the prediction model ####\n",
    "        self.generate_decision_tree(self.lr_bound['0'][0], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rU DONE\n",
      "Initiation DONE!\n"
     ]
    }
   ],
   "source": [
    "dtmodel_realdata = DecisionTreeModel(rating_matrix_csc[:, start:end], depth_threshold = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtmodel_realdata' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-edc78319101f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtmodel_realdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dtmodel_realdata' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "dtmodel_realdata.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import klepto\n",
    "Tree = klepto.archives.dir_archive('treeFile', cached=True, serialized=True)\n",
    "\n",
    "Tree['fmps_lr_bound'] = dtmodel_realdata.lr_bound\n",
    "Tree['fmps_tree'] = dtmodel_realdata.tree\n",
    "Tree['fmps_split_item'] = dtmodel_realdata.split_item\n",
    "\n",
    "Tree.dump()\n",
    "Tree.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-11-09 08:30:39'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.localtime(time.time())\n",
    "time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dtmodel_realdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class MatrixFactorization:\n",
    "    def __init__(self, maxIter=15, regParam=0.01, rank=10):\n",
    "        self.maxIter = maxIter\n",
    "        self.regParam = regParam\n",
    "        self.rank = rank\n",
    "        self.spark = SparkSession.builder.master(\"local[*]\").appName(\"Example\").getOrCreate()\n",
    "#         self.spark.conf.set(\"spark.driver.memory\", \"6g\")  \n",
    "        self.spark.conf.set(\"spark.executor.memory\", \"8g\")  \n",
    "        print(\"New SparkSession started...\")\n",
    "\n",
    "    def change_parameter(self, regParam):\n",
    "        self.regParam = regParam\n",
    "\n",
    "    def matrix_factorization(self, train_lst):\n",
    "        ratings = self.spark.createDataFrame(train_lst)\n",
    "        del train_lst\n",
    "        print(\"createDataFrame DONE\")\n",
    "        model = ALS.train(ratings, self.rank, seed=10, \\\n",
    "                          iterations=self.maxIter, \\\n",
    "                          lambda_=self.regParam)\n",
    "        print(\"MF DONE\")\n",
    "        userFeatures = sorted(model.userFeatures().collect(), key=lambda d: d[0], reverse=False)\n",
    "        productFeatures = sorted(model.productFeatures().collect(), key=lambda d: d[0], reverse=False)\n",
    "        userProfile = {each[0]: each[1].tolist() for each in userFeatures}\n",
    "        itemProfile = {each[0]: each[1].tolist() for each in productFeatures}\n",
    "\n",
    "        return userProfile, itemProfile\n",
    "\n",
    "    def end(self):\n",
    "        self.spark.stop()\n",
    "        print(\"SparkSession stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "val_num = rating_matrix_val_csc.getnnz(axis=None)\n",
    "########################################## For Validation #############################################\n",
    "def calculate_avg_rating_for_pesudo_user(pseudo_user_lst, sMatrix):\n",
    "\n",
    "    # ret_array = np.zeros(sMatrix.shape[0])\n",
    "    ret_array = np.array(sMatrix[:, pseudo_user_lst].sum(axis=1))[:,0]/(sMatrix[:, pseudo_user_lst].getnnz(axis=1)+1e-9)\n",
    "\n",
    "    return ret_array\n",
    "\n",
    "\n",
    "def pred_RMSE_for_validate_user(user_node_ind, user_profile, item_profile, val_user_list, val_item_list, sMatrix):\n",
    "    print(\"RMSE calculation on valset qstarted.\")\n",
    "    RMSE = 0\n",
    "    i = 0\n",
    "    for userid, itemid in zip(val_user_list, val_item_list):\n",
    "        if i % 50000 == 0:\n",
    "            print(\"%.2f%%\" % (100 * i / val_num))        \n",
    "        i += 1\n",
    "        RMSE += (sMatrix[itemid, userid] - np.dot(user_profile[user_node_ind[userid]], item_profile[itemid]))**2\n",
    "    return (RMSE / len(val_user_list))**0.5\n",
    "\n",
    "def generate_prediction_model(lr_bound, tree, rI, sMatrix, plambda_candidates, validation_set):\n",
    "    ''' lr_bound: dict {\n",
    "                level 0: [[left_bound, right_bound]], users' bound for one level, each ele in dictionary represents one node\n",
    "                level 1: [[left_bound, right_bound], [left_bound, right_bound], [left_bound, right_bound]], 3\n",
    "                level 2: ..., 9\n",
    "            } (bound means index)\n",
    "        plambda_candidates: {\n",
    "            level 0: [clambda1, clambda2, clambda3, ...]\n",
    "            level 1: [clambda1, clambda2, clambda3, ...]\n",
    "            level 2: [clambda1, clambda2, clambda3, ...]\n",
    "        }\n",
    "        prediction_model: dict {\n",
    "                level 0: { 'best_lambda': x, 'user_profile': ..., 'item_profile': ...}\n",
    "                level 1: { 'best_lambda': x, 'user_profile': ..., 'item_profile': ...}\n",
    "                level 2: { 'best_lambda': x, 'user_profile': ..., 'item_profile': ...}\n",
    "            }\n",
    "    '''\n",
    "    prediction_model = {}\n",
    "    \n",
    "#     val_item_list = find(validation_set)[0]\n",
    "#     val_user_list = find(validation_set)[1]\n",
    "    user_node_ind = np.zeros(sMatrix.shape[1])                  #### notice that index is not id\n",
    "    \n",
    "    for level in lr_bound:\n",
    "#        level = \"10\"\n",
    "        print(\"level:\", level)\n",
    "        prediction_model.setdefault(level, {})\n",
    "        train_lst = []       \n",
    "        for pseudo_user_bound, userid in zip(lr_bound[level], range(len(lr_bound[level]))):\n",
    "#             print(str(userid) + \"/\" + str(pow(3,int(level))))\n",
    "            if pseudo_user_bound[0] > pseudo_user_bound[1]:\n",
    "                continue\n",
    "            pseudo_user_lst = tree[pseudo_user_bound[0]:(pseudo_user_bound[1] + 1)]\n",
    "            pseudo_user_for_item = calculate_avg_rating_for_pesudo_user(pseudo_user_lst, sMatrix)\n",
    "            train_lst += [(userid, itemid, float(pseudo_user_for_item[itemid])) \\\n",
    "                          for itemid in range(pseudo_user_for_item.shape[0]) if pseudo_user_for_item[itemid]]    \n",
    "            #### find node index for each validation user ####\n",
    "            user_node_ind[pseudo_user_lst] = userid      \n",
    "\n",
    "        print(\"Rating Number of level \" + level + \": \" + str(len(train_lst)))\n",
    "        #### Train MF and Do validation ####\n",
    "#         min_RMSE = -1\n",
    "#         for plambda in plambda_candidates[level]:\n",
    "        MF = MatrixFactorization()\n",
    "        MF.change_parameter(plambda_candidates[level])\n",
    "        user_profile, item_profile = MF.matrix_factorization(train_lst)\n",
    "        MF.end()   #### close MF spark session\n",
    "#         RMSE = pred_RMSE_for_validate_user(user_node_ind, user_profile, item_profile, val_user_list, val_item_list, sMatrix)\n",
    "#         if min_RMSE is -1 or RMSE < min_RMSE:\n",
    "#         min_RMSE = RMSE\n",
    "        min_user_profile, min_item_profile, min_lambda = user_profile, item_profile, plambda_candidates[level]\n",
    "                \n",
    "        prediction_model[level]['upro'], prediction_model[level]['ipro'], prediction_model[level]['plambda'] \\\n",
    "                                             = min_user_profile, min_item_profile, min_lambda\n",
    "        print(\"level \" + level + \" training DONE\")\n",
    "    return prediction_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tree from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import klepto\n",
    "import numpy as np\n",
    "Tree = klepto.archives.dir_archive('treeFile', {}, serialized=True)\n",
    "Tree.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plambda_candidates = {\"0\":0.02,\n",
    "                     \"1\":0.02,\n",
    "                     \"2\":0.02,\n",
    "                     \"3\":0.02,\n",
    "                     \"4\":0.02,\n",
    "                     \"5\":0.02,\n",
    "                     \"6\":0.02,\n",
    "                     \"7\":0.02,\n",
    "                     \"8\":0.02,\n",
    "                     \"9\":0.02,\n",
    "                     \"10\":0.02}\n",
    "# for level in Tree[\"lr_bound\"]:\n",
    "#     plambda_candidates[level] = list(np.arange(0.001, 0.05, 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 0\n",
      "Rating Number of level 0: 17770\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MatrixFactorization' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c840515ec012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m prediction_model = generate_prediction_model             (Tree['lr_bound'],              Tree['tree'],              Tree['rI'],              rating_matrix_csc[:, start:end], \n\u001b[0;32m      2\u001b[0m              \u001b[0mplambda_candidates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m              rating_matrix_val_csc)    \n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-0aac46dafd51>\u001b[0m in \u001b[0;36mgenerate_prediction_model\u001b[1;34m(lr_bound, tree, rI, sMatrix, plambda_candidates, validation_set)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m#         min_RMSE = -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m#         for plambda in plambda_candidates[level]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mMF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatrixFactorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mMF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplambda_candidates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0muser_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix_factorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_lst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MatrixFactorization' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "prediction_model = generate_prediction_model \\\n",
    "            (Tree['lr_bound'], \\\n",
    "             Tree['tree'], \\\n",
    "             Tree['rI'], \\\n",
    "             rating_matrix_csc[:, start:end], \n",
    "             plambda_candidates, \n",
    "             rating_matrix_val_csc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f5da4a63e0d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mklepto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklepto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marchives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdir_archive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'treeFile'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction_model'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_model' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import klepto\n",
    "Tree = klepto.archives.dir_archive('treeFile', cached=True, serialized=True)\n",
    "Tree['prediction_model'] = prediction_model\n",
    "Tree.dump()\n",
    "Tree.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(real_rating, pred_rating, rated_item):\n",
    "    \n",
    "    non_zeros = list(np.nonzero(real_rating)[0])\n",
    "    non_zeros = list(set(non_zeros).difference(set(rated_item)))\n",
    "    if len(non_zeros) is 0:\n",
    "        return -1\n",
    "    rmse = (np.sum((pred_rating[non_zeros].T[0]-real_rating[non_zeros])**2))\n",
    "#     print(len(non_zeros))\n",
    "#     print(real_rating[non_zeros])\n",
    "#     print(pred_rating[non_zeros])\n",
    "#     print((pred_rating[non_zeros]-real_rating[non_zeros])**2)\n",
    "#     print(np.sum((pred_rating[non_zeros]-real_rating[non_zeros])**2))\n",
    "#     print((pred_rating[non_zeros]-real_rating[non_zeros]))\n",
    "#     print(rmse)\n",
    "    return (rmse/len(non_zeros))**0.5\n",
    "\n",
    "\n",
    "def predict(user_profile, item_profile):\n",
    "    ''' \n",
    "        user_profile: array {\n",
    "                        [k1, k2, k3, ... , kt]\n",
    "                    } profile for certain user\n",
    "        item_profile: dict {\n",
    "                        itemid1: [k1, k2, k3, ... , kt], \n",
    "                        itemid2: [k1, k2, k3, ... , kt], \n",
    "                        itemid3: [k1, k2, k3, ... , kt], \n",
    "                    } profile for items in each node\n",
    "     '''\n",
    "    #### Calculate predict rating ####\n",
    "    pred_rating = np.dot(item_profile, user_profile)\n",
    "    \n",
    "    return pred_rating\n",
    "\n",
    "def pred_RMSE_for_new_user(split_item, rI, prediction_model, sM_testing):\n",
    "    '''\n",
    "        sM_testing: 30% test dataset (sparse matrix)\n",
    "        split_item: list [\n",
    "                level 0: [112],\n",
    "                level 1: [48, 0, 79],\n",
    "                level 2: [15, 0, 17, 1, 1, 1, 61, 0, 50]\n",
    "                ...\n",
    "            ]\n",
    "        User: dict {\n",
    "                    userid1: { itemid11: rating11, itemid12: rating12, ... } rating of user 1\n",
    "                    userid2: { itemid21: rating21, itemid22: rating22, ... } rating of user 2\n",
    "                    userid3: ...\n",
    "                }\n",
    "        return : rmse value (float)\n",
    "    '''\n",
    "\n",
    "    sM_testing_0_discard = sM_testing[1:,:]\n",
    "    cnt_of_user = sM_testing.shape[1]\n",
    "    rmse = []\n",
    "    for userid in range(sM_testing.shape[1]):\n",
    "        if userid % 100 == 0:\n",
    "            print(\"%.2f%%\" % (100 * userid / sM_testing.shape[1]))  \n",
    "        pred_index = 0\n",
    "        final_level = 0\n",
    "        rated_item = []\n",
    "        user_all_ratings = sM_testing[:,userid].nonzero()[0]\n",
    "#         print(\"Step1 start:\")\n",
    "        attitude = []\n",
    "        for level in range(len(split_item)):\n",
    "            if split_item[level][pred_index] not in user_all_ratings:\n",
    "                attitude.append('U')\n",
    "                tmp_pred_index = 3*pred_index + 2\n",
    "                if tmp_pred_index in prediction_model[str(int(level)+1)]['upro']:\n",
    "                    final_level += 1\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break\n",
    "            elif sM_testing[split_item[level][pred_index], userid] >= 4:\n",
    "                attitude.append('L')\n",
    "                tmp_pred_index = 3*pred_index\n",
    "                if tmp_pred_index in prediction_model[str(int(level)+1)]['upro']:\n",
    "                    rated_item.append(split_item[level][pred_index]-1)\n",
    "                    final_level += 1\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break\n",
    "            elif sM_testing[split_item[level][pred_index], userid] <= 3:\n",
    "                attitude.append('D')\n",
    "                tmp_pred_index = 3*pred_index + 1\n",
    "                if tmp_pred_index in prediction_model[str(int(level)+1)]['upro']:\n",
    "                    rated_item.append(split_item[level][pred_index]-1)\n",
    "                    final_level += 1\n",
    "                    pred_index = tmp_pred_index\n",
    "                else:\n",
    "                    break        \n",
    "\n",
    "#         print(\"Step2 start:\")\n",
    "        pred_rating = predict(np.array(prediction_model[str(final_level)]['upro'][pred_index]), \\\n",
    "                                            np.array(list(prediction_model[str(final_level)]['ipro'].values()))) \n",
    "#         print(\"Step3 start:\")\n",
    "#         print(pred_rating)\n",
    "#         print(sM_testing_0_discard[:, userid].toarray())\n",
    "        tmp_rmse = RMSE(sM_testing_0_discard[:, userid].toarray(), pred_rating, rated_item)    \n",
    "        # print(str(userid)+\": \", attitude, tmp_rmse)\n",
    "        if tmp_rmse != -1:\n",
    "            rmse.append(tmp_rmse)\n",
    "    return rmse\n",
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import klepto\n",
    "import numpy as np\n",
    "Tree = klepto.archives.dir_archive('treeFile', {}, serialized=True)\n",
    "Tree.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "b'content'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/rcg/software/Linux/Ubuntu/16.04/amd64/LANG/PYTHON/3.5.2-SYSTEM/lib/python3.5/shelve.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-852550d9ebe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshelve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshelve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrmse_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_RMSE_for_new_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split_item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating_matrix_csc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/rcg/software/Linux/Ubuntu/16.04/amd64/LANG/PYTHON/3.5.2-SYSTEM/lib/python3.5/shelve.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: b'content'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import pickle\n",
    "import shelve\n",
    "d = shelve.open(\"prediction_model\", protocol=pickle.HIGHEST_PROTOCOL)\n",
    "prediction_model = d['content']\n",
    "rmse_result = pred_RMSE_for_new_user(Tree['split_item'][:10], Tree[\"rI\"], prediction_model, rating_matrix_csc[:, end:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rmse_result)/len(rmse_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}